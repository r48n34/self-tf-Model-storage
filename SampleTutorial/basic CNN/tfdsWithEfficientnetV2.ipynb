{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf9XGUGN3Eif",
        "outputId": "86856bd9-06c3-46e2-c12d-99c3cba4e558"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaKEF90T3NK2",
        "outputId": "67545f1f-e599-4c59-93c2-3a4bdf930cd3"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3MCpKXv3OHF",
        "outputId": "0e82eb7c-d467-40e4-9a73-9bfcb8c1df56"
      },
      "outputs": [],
      "source": [
        "# https://github.com/leondgarse/keras_efficientnet_v2\n",
        "!pip install -U keras-efficientnet-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "HqBqSijC3O8K"
      },
      "outputs": [],
      "source": [
        "import keras_efficientnet_v2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "uKZH4m_A3STS"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "imgSize = 240\n",
        "\n",
        "# Construct a tf.data.Dataset\n",
        "(train_ds, valid_ds) , ds_info = tfds.load('oxford_flowers102', split=['test', 'train'], shuffle_files=True, as_supervised=True, with_info=True)\n",
        "\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n",
        "classArr = ds_info.features[\"label\"].names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "jSyR6nGY3UlM"
      },
      "outputs": [],
      "source": [
        "# data_augmentation = keras.Sequential(\n",
        "#   [\n",
        "#     tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "#     tf.keras.layers.RandomRotation(0.1),\n",
        "#     tf.keras.layers.RandomZoom(0.1),\n",
        "#     #tf.keras.layers.RandomContrast(0.1),\n",
        "#   ]\n",
        "# )\n",
        "\n",
        "trainDsTranform = keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.Resizing(imgSize, imgSize),\n",
        "    tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
        "  ]\n",
        ")\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  tf.keras.layers.Resizing(imgSize, imgSize),\n",
        "  tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "fPqYV80k3Ymj"
      },
      "outputs": [],
      "source": [
        "expendRound = 2\n",
        "temp_ds = train_ds\n",
        "for i in range(expendRound):\n",
        "    train_ds = train_ds.concatenate(temp_ds)\n",
        "\n",
        "#train_ds = train_ds.map(lambda image,label:(data_augmentation(image),label)).batch(32)\n",
        "train_ds = train_ds.map(lambda image,label:(trainDsTranform(image),label)).batch(batch_size)\n",
        "\n",
        "\n",
        "valid_ds = valid_ds.map(lambda image,label:(resize_and_rescale(image),label)).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE0qCfii31Id",
        "outputId": "faaa41ac-01f0-4345-c941-d70377116125"
      },
      "outputs": [],
      "source": [
        "baseModel = keras_efficientnet_v2.EfficientNetV1B1(pretrained=\"noisy_student\", num_classes=NUM_CLASSES, drop_connect_rate=0.3)\n",
        "\n",
        "baseModel.trainable = True\n",
        "print(\"Layers count\", len(baseModel.layers))\n",
        "\n",
        "fine_tune_at = int( len(baseModel.layers) * 0.50) \n",
        "for layer in baseModel.layers[:fine_tune_at]:\n",
        "   layer.trainable = False\n",
        "  \n",
        "epochsRound = 14\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "checkpoint_filepath = './tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "baseModel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = baseModel.fit(train_ds, epochs=epochsRound, validation_data=valid_ds, callbacks=[model_checkpoint_callback], batch_size=batch_size)\n",
        "\n",
        "test_loss, test_acc = baseModel.evaluate(valid_ds, verbose=2)\n",
        "print(test_acc)\n",
        "\n",
        "now = datetime.now()\n",
        "current_time = now.strftime(\"%b-%d-%Y_%H:%M:%S\")\n",
        "srt = \"/content/drive/MyDrive/savedModel/\" + \"efficientnetV1B0\" + current_time + \".h5\"\n",
        "\n",
        "baseModel.load_weights(checkpoint_filepath)\n",
        "baseModel.save(srt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b6DBEP-Uo5g"
      },
      "outputs": [],
      "source": [
        "y_pred = baseModel.predict(valid_ds)\n",
        "predicted_categories = tf.argmax(y_pred, axis=1)\n",
        "true_categories = tf.concat([lab for img, lab in valid_ds], axis=0)\n",
        "report = classification_report(predicted_categories, true_categories, target_names=classArr, zero_division=0, digits=4)\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MLdYRSu4K4V"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochsRound)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IeIFYfS5IYI"
      },
      "source": [
        "# References  \n",
        "\n",
        "1. Keras EfficientNetV2:  \n",
        "https://github.com/leondgarse/keras_efficientnet_v2  \n",
        "2. Transfer learning and fine-tuning  \n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning?hl=zh-tw  \n",
        "3. Training a neural network on MNIST with Keras  \n",
        "https://www.tensorflow.org/datasets/keras_example\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tfdsWithEfficientnetV2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
