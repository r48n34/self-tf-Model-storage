{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiClassesBERTofficial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "036aMuPkXIsD"
      },
      "source": [
        "!pip install -q -U tensorflow-text\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dna7kV9PXMki"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abezdy3MvYe3"
      },
      "source": [
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "\n",
        "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n",
        "                                  untar=True, cache_dir='.',\n",
        "                                  cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "\n",
        "# remove unused folders to make it easier to load the data\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsPE5j_sXof3"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', label_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed)\n",
        "\n",
        "classNum = int(len(raw_train_ds.class_names))\n",
        "class_names = raw_train_ds.class_names\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', label_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)\n",
        "\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/test', label_mode='categorical',\n",
        "    batch_size=batch_size)\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x3usyb8ZTyc"
      },
      "source": [
        "# Find in modelList.py\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  \n",
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okfr9uUBfjeH"
      },
      "source": [
        "#print\n",
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print(f'Review: {text_batch.numpy()[i]}')\n",
        "    label = label_batch.numpy()[i]\n",
        "    print(f'Label : {label} ({class_names[label]})')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTSo5z0OZVtm",
        "outputId": "5f32ee7c-a85b-49f9-f180-26cd2bb34f2d"
      },
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(64, activation='relu')(net)\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(classNum, activation='softmax', name='classifier')(net)\n",
        "\n",
        "  return tf.keras.Model(text_input, net)\n",
        "\n",
        "classifier_model = build_classifier_model()\n",
        "classifier_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'default': (None,   28763649    ['preprocessing[0][0]',          \n",
            "                                512),                             'preprocessing[0][1]',          \n",
            "                                 'sequence_output':               'preprocessing[0][2]']          \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 512),                                               \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 512)}                                                       \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 512)          0           ['BERT_encoder[0][5]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64)           32832       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 2)            130         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,796,611\n",
            "Trainable params: 28,796,610\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kcuio1xKZ3rU",
        "outputId": "9ad95a0e-234a-4217-a4c8-197f269bac35"
      },
      "source": [
        "#bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "\n",
        "tf.keras.utils.plot_model(classifier_model)\n",
        "\n",
        "epochs = 3\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr, num_train_steps=num_train_steps,\n",
        "        num_warmup_steps=num_warmup_steps, optimizer_type='adamw')\n",
        "\n",
        "\n",
        "classifier_model.compile(\n",
        "    optimizer=optimizer,\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x=train_ds, validation_data=val_ds,\n",
        "                          epochs=epochs)\n",
        "\n",
        "loss, accuracy = classifier_model.evaluate(test_ds)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "dataset_name = 'imdb'\n",
        "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
        "classifier_model.save(saved_model_path, include_optimizer=False)\n",
        "reloaded_model = tf.saved_model.load(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Epoch 1/3\n",
            "625/625 [==============================] - 150s 234ms/step - loss: 0.4809 - accuracy: 0.7588 - val_loss: 0.3633 - val_accuracy: 0.8370\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 139s 223ms/step - loss: 0.3235 - accuracy: 0.8602 - val_loss: 0.3645 - val_accuracy: 0.8460\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 138s 220ms/step - loss: 0.2587 - accuracy: 0.8935 - val_loss: 0.3875 - val_accuracy: 0.8472\n",
            "782/782 [==============================] - 103s 131ms/step - loss: 0.3734 - accuracy: 0.8550\n",
            "Loss: 0.3733615279197693\n",
            "Accuracy: 0.8550400137901306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 310). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxOprCwXPxRt"
      },
      "source": [
        "def print_my_examples(inputs, results):\n",
        "  result_for_printing = \\\n",
        "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
        "                         for i in range(len(inputs))]\n",
        "  print(*result_for_printing, sep='\\n')\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrkY5ENfEM9E",
        "outputId": "e29030a7-b152-4e31-ab53-49cca6c43dd2"
      },
      "source": [
        "examples = [\n",
        "    'this is such an amazing movie!',  # this is the same sentence tried earlier\n",
        "    'The movie was great!',\n",
        "    'The movie was meh.',\n",
        "    'The movie was okish.',\n",
        "    'The movie was terrible...'\n",
        "    'i don\\'t think that is a good show',\n",
        "    'what a shame that a directer make that film',\n",
        "    'Actually that is quite decent as a indivual movie'\n",
        "]\n",
        "\n",
        "#reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
        "# original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
        "original_results2 = tf.nn.softmax(classifier_model(tf.constant(examples)))\n",
        "\n",
        "# print('Results from the model in memory:')\n",
        "# print_my_examples(examples, original_results)\n",
        "\n",
        "print('Results from the model in memory:')\n",
        "print_my_examples(examples, original_results2)\n",
        "\n",
        "#test_loss, test_acc = classifier_model.evaluate(val_ds, verbose=2)\n",
        "\n",
        "preLabel = ['neg', 'pos']\n",
        "a = classifier_model.predict( tf.constant(examples) )\n",
        "\n",
        "#print(a)\n",
        "\n",
        "for i in a:\n",
        "  print( preLabel[tf.argmax(i)] , i)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results from the model in memory:\n",
            "input: this is such an amazing movie! : score: 0.270227\n",
            "input: The movie was great!           : score: 0.273231\n",
            "input: The movie was meh.             : score: 0.369795\n",
            "input: The movie was okish.           : score: 0.684780\n",
            "input: The movie was terrible...i don't think that is a good show : score: 0.730501\n",
            "input: what a shame that a directer make that film : score: 0.697626\n",
            "input: Actually that is quite decent as a indivual movie : score: 0.367626\n",
            "\n",
            "pos [0.00326373 0.9967362 ]\n",
            "pos [0.01085467 0.9891453 ]\n",
            "pos [0.23345192 0.76654804]\n",
            "neg [0.88791424 0.11208577]\n",
            "neg [0.9985832  0.00141687]\n",
            "neg [0.9180102  0.08198986]\n",
            "pos [0.22879241 0.77120763]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HnH9tDG0Z_J"
      },
      "source": [
        "# References  \n",
        "https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
      ]
    }
  ]
}